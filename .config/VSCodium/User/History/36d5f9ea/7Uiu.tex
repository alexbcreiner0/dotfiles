\documentclass{beamer}

\usepackage{fancyvrb}
\makeatletter
\def\KV@FV@lastline@default{%
  \let\FancyVerbStopNum\m@ne
  \let\FancyVerbStopString\relax}
\fvset{lastline}
\makeatother
\usepackage{listings}
\usepackage{minted}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{bm}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
    }

\urlstyle{same}
\usetheme{Madrid}

\title{Complexity Theory and NP-Completeness}
\author{Alex Creiner}

\institute{Boston College}
\date{Spring 2024}

\begin{document}

\titlepage
\begin{frame}{Introduction}
    \begin{itemize}
        \item We now turn towards a brief overview of complexity theory more broadly, with the nominal purpose of noting a particular set of especially difficult problems, and how to tell if the problem you are trying to solve is one of them. 
        \item If this material interests you, consider taking my complexity theory elective next spring! 
    \end{itemize}
\end{frame}

\begin{frame}{Decision Problems}
    \begin{itemize}
        \item For the sake of simplicity, computational complexity theorists generally focus on a specific kind of problem known as a \textbf{decision problem}. A decision problem is a problem in which the answer is always a Boolean value: Yes or no, true or false, etc. \pause 
        \item Examples:
        \begin{itemize}
            \item The factoring problem: Given an integer $x$, does it have a non-trivial prime factor? (Non-trivial means not $1$) \pause 
            \item The satisfiability problem (SAT): Given a Boolean expression with $n$ many variables $\phi$, does there exist an assignment of truth values to those variables which makes the expression evaluate to true? (For example, $(x_1 \wedge x_2)\vee \neg x_3$ is satisfiable by setting $x_1$ and $x_2$ equal to True, and $x_3$ equal to false). \pause
            \item The graph isomorphism problem: Given two graphs, is one actually just a relabelling of the nodes of the other? \pause 
        \end{itemize}
        \item The middle of these, $SAT$, is particularly important to us. Don't forget about it. 
    \end{itemize}
\end{frame}

\begin{frame}{Decision Problems}
    \begin{itemize}
        \item Most non-decision problems have a decision problem which can be expressed in place of it, which encapsulates the complexity of the original. \pause 
        \item For example, the travelling salesman problem (TSP) is an optimization problem: Given a complete weighted graph, what is the shortest path which touches every node exactly once? \pause
        \item The decision problem `version' of this is the problem: Given a complete weighted graph and a length $d$, does there exist a path which reaches every node exactly once and which has total length $\leq d$? \pause 
        \item Through the magic of binary search, a solution to the decision problem version of TSP can be utilized to produce a solution to the original optimization question without much time overhead. \pause 
        \item In this way, we should see decision problems as standing in for all other kinds of problems in order to simplify the discussion. 
    \end{itemize}
\end{frame}

\begin{frame}{Some basic complexity classes: \textbf{R}}
    \begin{itemize}
        \item We can now define some basic complexity classes. 
        \item First, we've already briefly mentioned the set of all computable decision problems, $\mathbf{R}$. This is actually a tiny subset of the universe of all decision problems; most problems are \emph{not} computable at all! \pause 
        \item A famous example is the halting problem: Given the code for a computer program and an input to it, will the program ever halt on that input? (I.e. will there not be an infinite loop of some sort?) 
        \item When I teach logic and computation, I always make it a goal to prove that this problem is not computable. 
    \end{itemize}
\end{frame}

\begin{frame}{Some basic complexity classes \textbf{P} and \textbf{EXP}}
    \begin{itemize}
        \item Next, the class $\mathbf{P}$ is the set of all problems which are computable in \textbf{polynomial time}. I.e. a decision problem $L$ is in $\mathbf{P}$ iff there is an algorithm which solves it in time $O(n^k)$ for some $k \in \mathbb{Z}$. 
        \item We've spent the entire class so far safe and cozy within this class. Most of our algorithms usually end up operating in time $O(n^2)$, or $O(n\log(n))$, or $O(n^3)$, etceteral. These are all in $\mathbf{P}$. 
        \item On the other hand, $\mathbf{EXP}$ is the set of problems which are computable in $\textbf{exponential time}$, i.e. time $O(2^{n^k})$ for some $k \in \mathbb{Z}$. 
        \item Since any polynomial time is also exponential time, $\mathbf{P} \subseteq \mathbf{EXP}$. It follows that anything proven to be in $\mathbf{EXP}$ but not in $\mathbf{P}$ could be labelled as an exceptionally difficult problem. Are there any known examples?
    \end{itemize}
\end{frame}

\begin{frame}{Complexity classes continued}
    \begin{itemize}
        \item Plenty! My personal go-to example is generalized chess. Given an $n \times n$ chess board and some configuration of the pieces on that board, does player $1$ have a winning strategy? I.e. is there a move that player $1$ can make so that no matter what move player $2$ makes, there is a move that player $1$ can make so that no matter what move player $2$ makes... etc, until player $1$ wins?
        \item This problem can be proven to be in $\mathbf{EXP}$. In fact, it is $\mathbf{EXP}$-\textbf{complete}. Let's define what that means. \pause 
        \item A problem $P$ is \textbf{hard} for a complexity class if any problem $Q$ in that class can be reduced to $P$ in polynomial time. (i.e. the pre and post-processing required is efficiently computable). 
    \end{itemize}
\end{frame}

\begin{frame}{Completeness}
    \begin{itemize}
        \item If the problem $P$ is itself a member of that complexity class which it is hard for, then we say it is \textbf{complete} for that class. Thus, an $\mathbf{EXP}$-complete problem is representative of the hardest problems in $\mathbf{EXP}$. They represent the maximum difficulty of any problem in the class. Many other games can be proven to be $\mathbf{EXP}$-complete, such as GO. 
        \item I snuck in there that we are assuming all problems in $\mathbf{P}$ to be `efficiently solvable'. That is a pretty major departure from the attitude we've had throughout this class, which is that $O(n^2)$ is `slow'. However, zooming out to this much more encompassing definition of reasonable time complexity gives us some perspective we wouldn't otherwise be able to gain. 
    \end{itemize}
\end{frame}

\begin{frame}{PSPACE}
    \begin{itemize}
        {\small \item The class $\mathbf{PSPACE}$ is the set of all problems which are computable in polynomial \emph{space}. Simple enough. \pause 
        \item One thing which can be immediately noted is that $\mathbf{P} \subseteq \mathbf{PSPACE}$. Why? \pause 
        \item Answer: In time $O(f(n))$ how could you possibly use up space greater than $O(f(n))$ you have to record information down in memory to use space, and you only have $f(n)$ time to do that!
        \item Whether or not $\mathbf{PSPACE} \subseteq \mathbf{P}$ is an open question. However, there is plenty of evidence towards the answer being no. (Still, never say never.) 
        \item However, $\mathbf{PSPACE} \subseteq \mathbf{EXP}$, and provably different. Chess, for example, is in $\mathbf{EXP}$ but not in $\mathbf{P}$. If you want to see why, take my class next spring. 
        \item In fact, $\mathbf{PSPACE}$ is typically regarded as marking the boundary point of anything which could be considered efficiently computable in any way. Outside of $\mathbf{PSPACE}$, nothing is easy. }
    \end{itemize}
\end{frame}

\begin{frame}{NP}
    \begin{itemize}
        \item Finally, let's turn to $\mathbf{NP}$. This is an abbreviation for \textbf{non-deterministic polynomial time}. There are a lot of different ways to conceptualize this class. 
        \item From a practical standpoint, the discussion of $\mathbf{NP}$ is the discussion of the role of \emph{searching} in computer science. We've seen repeatedly in this class a functional equivalence between \emph{searching} and \emph{guessing}. If we have a program that can quickly search for an answer and return it, then from the perspective of $\mathbf{P}$, we might as well have had the program just magically guess the answer in one step. Fast searching is functionally equivalent to guessing. 
        \item What kinds of problems would be efficiently solvable if we had an incredibly lucky machine which could always magically search through a very large set of things for us? Or, equivalently, if we had an incredibly lucky machine that could always guess a thing and have it be what we wanted?
    \end{itemize}
\end{frame}

\begin{frame}{NP continued}
    \begin{itemize}
        \item Sudoku. It would be very hard to program a computer to solve a sudoku puzzle for us. However, what if we guessed at a solution? If we guess, and guess correctly, then it would be \emph{easy} (and \emph{fast}) to \emph{confirm} that our guess was correct. \pause 
        \item This is one way to formulate the class $\mathbf{NP}$: The set of problems such that you can \emph{check to see if you have the right answer} in polynomial time. 
        \item Another example is the Boolean satisfiability problem we mentioned earlier. Given a Boolean expression on $n$ variables, there are $2^n$ possible truth assignments. It would take a long, long time to search through all of these, but \emph{if we could}, or \emph{if we guessed correctly on the first try}, then we could easily confirm in linear time that the answer is yes. 
    \end{itemize}
\end{frame}

\begin{frame}{NP continued}
    \begin{itemize}
        \item So that is $\mathbf{NP}$. $\mathbf{NP}$ is:
        \begin{itemize}
            \item The set of problems such that the solutions can be confirmed in polynomial time.
            \item The set of problems which are efficiently computable \emph{up to} a search subroutine over a very large set.
        \end{itemize}
        \item ($\mathbf{NP}$ is also the set of problems which are computable in polynomial time by a nondeterministic Turing machine; take my class in the spring if you want to know what this means.) 
        \item Clearly, $\mathbf{P} subseteq \mathbf{NP}$. If you had a polynomial time algorithm for producing a solution, and someone handed you a solution, then you could simply run that polynomial time algorithm and see if you get what they handed you!
        \item It's also pretty clear that $\mathbf{NP} \nsubseteq \mathbf{P}$. Why should there be an efficient algorithm for a problem just because there is an efficient way to confirm solutions? Except...
        \item Nobody has ever been able to actually prove this. The question of whether or not $\mathbf{P} = \mathbf{NP}$ is

    \end{itemize}
\end{frame}

\begin{frame}{co-NP}
    \begin{itemize}
        \item Notice the bias here in one direction. We are only saying that solutions can be \emph{confirmed} in polynomial time. We are \emph{not} saying that you can rule out non-solutions in polynomial time. That would be the class $\mathbf{co-NP}$, and these classes are almost certainly different. 
    \end{itemize}

\end{frame}

\end{document}